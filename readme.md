# TP1 - S2 d'Algorithmique : Algorithmes de Graphes & Structures de Donn√©es

## üì¶ Installation

1. Clone ce d√©p√¥t :
```bash
git clone https://github.com/ton-utilisateur/ton-projet.git
cd ton-projet
```

# Configuration du json

```json
{
  "matrice_start": "",
  "matrice_end": "",
  "matrice": {
    "A": {"B": 4, "C": 2},
    "B": {"A": 4, "D": 5},
    "C": {"A": 2, "E": 3},
    "D": {"B": 5, "F": 6},
    "E": {"C": 3},
    "F": {"D": 6}
  }
}
```

`matrice_start` : sommet de d√©part pour le parcours du graphe<br>
`matrice_end` : sommet de fin pour le parcours du graphe<br>
`matrice` : repr√©sentation du graphe sous forme de dictionnaire o√π chaque cl√© est un sommet et la valeur est un dictionnaire des voisins avec les poids des ar√™tes.<br>
`rand_list`: List utilis√©e pour le tri<br>
`tree`: D√©clarer un arbre<br>
`number_list`: D√©clarer une liste de nom √† inserrer  dans l'arbre<br>
`sat_clauses`: <br>
`tsp_matrix`: <br>

# Lancement

## Via le menu
```bash
python -m app.main
```

## Via CLI
```bash
python -m app.main -h
```

# Exercice 1 : Recherche et Parcours de Graphes
## Le [BFS](./algos/bfs.py)
1. Execution
```bash
python -m app.main bfs
```
2. Temps d'√©x√©cution

Le BFS s'√©xecute en 0.99ms avec le graphe donn√©

3. Compl√©xit√©

Le BFS a une complexit√© temporelle de O(V + E) o√π V est le nombre de sommets et E le nombre d'ar√™tes du graphe. En effet, chaque sommet est visit√© une fois et chaque ar√™te est examin√©e une fois.

La complexit√© spatiale est √©galement O(V) car on doit stocker les sommets visit√©s et la file d'attente.

## Le DFS [dfs](./algos/dfs.py)
1. Execution
```bash
python -m app.main dfs
```
2. Temps d'√©x√©cution

Le DFS s'√©xecute en 0.99ms avec le graphe donn√©

3. Compl√©xit√©

Le DFS a une complexit√© temporelle de O(V + E) o√π V est le nombre de sommets et E le nombre d'ar√™tes du graphe. En effet, chaque sommet est visit√© une fois et chaque ar√™te est examin√©e une fois.
La complexit√© spatiale est O(V) car on doit stocker les sommets visit√©s et la pile d'appels r√©cursive.

## BFS avec d√©tection des composantes connexes [bfs connexe](./algos/bfs.py)
```bash
python -m app.main bfs-connexe 
```

## DFS avec d√©t√©ction de cycle [dfs cycle](./algos/dfs.py)
```bash
python -m app.main dfs_cycle
```
## Pr√©f√©rence du DFS ou du BFS

TODO

# Exercice 2 : Algorithme de Dijkstra

1. Ecriture du pseudo code
```
Entr√©e :
    - G : graphe avec sommets et ar√™tes pond√©r√©es
    - S : sommet de d√©part

Initialisation :
    Pour chaque sommet v dans G :
        distance[v] ‚Üê ‚àû
    distance[S] ‚Üê 0

    file_priorit√© ‚Üê file vide (ex: tas binaire)
    ins√©rer (0, S) dans file_priorit√©   // (distance, sommet)

    visit√© ‚Üê ensemble vide

Tant que file_priorit√© n‚Äôest pas vide :
    (d, u) ‚Üê extraire_min(file_priorit√©)

    Si u ‚àà visit√© :
        continuer

    ajouter u √† visit√©

    Pour chaque voisin v de u :
        poids ‚Üê poids de l‚Äôar√™te (u, v)

        Si distance[u] + poids < distance[v] :
            distance[v] ‚Üê distance[u] + poids
            ins√©rer (distance[v], v) dans file_priorit√©

Retourner distance

```

2. Impl√©mentation de l'algorithme [dijkstra](./algos/dijkstra.py)
```bash
python -m app.main dijkstra
```

3. R√©solution du probl√®me du plus court chemin

En appliquant l‚Äôalgorithme de Dijkstra depuis le sommet A, on obtient les distances minimales suivantes vers les autres sommets :
- A ‚Üí B : 4
- A ‚Üí C : 2
- A ‚Üí D : 9
- A ‚Üí E : 5
- A ‚Üí F : 15
Ces r√©sultats repr√©sentent les plus courts chemins en termes de co√ªt total (somme des poids).

NB: la comparaise avec bellman ford et fair dans le 6. de la partie [Bellman-Ford](#exercice-3--algorithme-de-bellman-ford)

4. Analyse de la complexit√©

L'algorithme de Dijkstra a une complexit√© temporelle de O((V + E) * log(V)) o√π V est le nombre de sommets et E le nombre d'ar√™tes du graphe.
La complexit√© temporelle s'explique par le fait que chaque sommet est visit√© une fois et chaque ar√™te est examin√©e une fois. De plus, l'utilisation d'une file de priorit√© permet d'optimiser la recherche du sommet avec la distance minimale.

La complexit√© spatiale est O(V) car on doit stocker les sommets visit√©s et la file de priorit√©.

# Exercice 3 : Algorithme de Bellman-Ford


1. Pseudo code pour de Bellman-Ford

```
Entr√©e :
    - G : graphe avec sommets et ar√™tes pond√©r√©es
    - S : sommet de d√©part

Initialisation :
    Pour chaque sommet v dans G :
        distance[v] ‚Üê ‚àû
    distance[S] ‚Üê 0

    Pour i allant de 0 √† nombre de sommet du graph - 1 : 
        Pour chaque sommet V dans G :
            Pour chaque voisin N de V :
                W <- poids entre V et N
                Si dinstance[V] + poid < distance[N] alors
                    distance[N] <- distance[V] + W
                fin Si
            Fin pour chaque
        Fin pour chaque
    Fin pour chaque

    # D√©tection des cycle n√©gatif
    Pour chaque sommet V dans G :
         Pour chaque voisin N de V :
            W <- poids entre V et N
            # S'il est encore possible d'am√©liorer les distance, alors le graph contuent un cycle n√©gatif
            Si distance[V] + W < distance[N] alors
                renvoyer "Le graph √† un cycle n√©gatif"
            Fin si
        fin pour chaque
    Fin pour chaque
    # Fin de la d√©tection de cycle n√©gatif

retourner distance
```

2. Impl√©mentation et test de l'algorithme [bellman-ford](./algos/bellman-ford.py)
```bash
python -m app.main bf
```

3. D√©tection des cycles n√©gatif

La d√©tection des cycles n√©gatif se fait gr√¢ce √† la boucle suivante dans le pseudo-code
```
# D√©tection des cycle n√©gatif
    Pour chaque sommet V dans G :
         Pour chaque voisin N de V :
            W <- poids entre V et N
            # S'il est encore possible d'am√©liorer les distance, alors le graph contuent un cycle n√©gatif
            Si distance[V] + W < distance[N] alors
                renvoyer "Le graph √† un cycle n√©gatif"
            Fin si
        fin pour chaque
    Fin pour chaque
    # Fin de la d√©tection de cycle n√©gatif
```

Comment cela fonctionne ?
> Gr√†ce √† l'instruction `Pour i allant de 0 √† nombre de sommet du graph - 1` dans le pseudo-code, les distance minimal vont se propager jusqu'√† sommets les plus loins. Si il est encore possible d'am√©liorer ce r√©sultat alors que toutes les distances ont √©t√© propag√©es au plus loins, alors le graph contient un cycle n√©gatif.

Lancement du code

```bash
python -m app.main bf-neg
```

4. Les cycles n√©gatif dans la pratique
Les cycles n√©gatif ne peuvent pas s'appliquer dans les r√©seaux informatique car les distances ou les couts sont physique donc par d√©finition toujours positifs.

Dans un jeu vid√©o, un cycle n√©gatif peut repr√©senter une boucle d‚Äôactions o√π le joueur gagne constamment des points ou des ressources, ce qui casse l‚Äô√©quilibre du jeu.
> Exemple : Dans un RPG, un joueur d√©couvre qu‚Äôil peut acheter une potion pour 5 pi√®ces d‚Äôor, la revendre pour 6 pi√®ces dans une autre ville, puis revenir ‚Äî en boucle ‚Äî gagnant 1 pi√®ce √† chaque cycle sans fin. Ce cycle √©conomique "achete ‚Üí voyage ‚Üí revend ‚Üí revient" correspond √† un cycle n√©gatif de co√ªt qui exploite une faille dans l'√©quilibrage du jeux.

5. Analyse de complexit√©

La complexit√© temporelle de Bellman-Ford est O(VE), car on parcourt toutes les ar√™tes E pendant V - 1 it√©rations (o√π V est le nombre de sommets). Cela donne une complexit√© de O((V - 1) * E), et comme le -E est n√©gligeable face √† VE, on retient O(VE).

La complexit√© spatiale est O(V), car on stocke uniquement un tableau (ou dictionnaire) de distances pour chaque sommet.

6. Comparaison avec Dijkstra

L‚Äôalgorithme de Bellman-Ford permet de calculer les plus courts chemins depuis un sommet, m√™me en pr√©sence de poids n√©gatifs, et peut d√©tecter les cycles de poids n√©gatif. En revanche, il est plus lent avec une complexit√© en temps de O(VE). L‚Äôalgorithme de Dijkstra est plus rapide (O((V + E) log V)) mais ne fonctionne que si tous les poids sont positifs. Dijkstra est donc souvent pr√©f√©r√© pour les graphes classiques (r√©seaux, cartes), tandis que Bellman-Ford est utile pour des cas plus g√©n√©raux ou complexes. Le choix d√©pend du type de graphe et des contraintes sur les poids.

# Exercice 4 : l'algorithmes de Ford-Fulkerson et Edmonds-Karp

1. Pseudo code Ford-Fulkerson

```
fonction BFS(source, puits, graph, parent):
    initialiser file ‚Üê [source]
    initialiser ensemble visit√© ‚Üê {source}
    tant que la file n‚Äôest pas vide :
        u ‚Üê retirer un sommet de la file
        pour chaque voisin v de u :
            si v non visit√© et capacit√© r√©siduelle (u, v) > 0 :
                file ‚Üê file + [v]
                parent[v] ‚Üê u
                ajouter v √† visit√©
                si v == puits :
                    retourner Vrai
    retourner Faux

fonction FordFulkerson(graph, source, puits):
    initialiser parent[v] ‚Üê None pour chaque sommet v
    flot_max ‚Üê 0

    tant que BFS(source, puits) retourne Vrai :
        chemin ‚Üê chemin reconstruit depuis parent
        flot_chemin ‚Üê capacit√© minimale sur ce chemin
        pour chaque ar√™te (u, v) du chemin :
            diminuer capacit√© de (u, v) de flot_chemin
            augmenter capacit√© de (v, u) de flot_chemin
        flot_max ‚Üê flot_max + flot_chemin

    retourner flot_max
```


2. Impl√©mentation et test de l'algorithme [Ford-Fulkerson](./algos/ff.py)
```bash
python -m app.main ff
```

3. Analyse de la complexit√© de l'algorithme Ford-Fulkerson

La complexit√© temporelle de l‚Äôalgorithme de Ford-Fulkerson d√©pend du nombre d‚Äôit√©rations n√©cessaires pour atteindre le flot maximal. √Ä chaque it√©ration, on cherche un chemin augmentant, ce qui prend O(E) dans le cas d‚Äôune recherche en profondeur (DFS), et le flot est augment√© d‚Äôau moins une unit√© √† chaque fois. Si le flot maximum est F, la complexit√© temporelle est donc O(F √ó E).

La complexit√© spatiale, l‚Äôalgorithme utilise un dictionnaire pour suivre les parents des sommets soit O(V).

4. Pseudo code Edmonds-Karp

```
fonction BFS(source, puits,  graph, parent):
    cr√©er une file queue ‚Üê [source]
    cr√©er un ensemble visit√© ‚Üê {source}
    tant que queue n‚Äôest pas vide :
        u ‚Üê queue.pop()
        pour chaque voisin v de u :
            si v non visit√© et capacit√© r√©siduelle graph[u][v] > 0 :
                parent[v] ‚Üê u
                ajouter v √† queue
                ajouter v √† visit√©
                si v = puits :
                    retourner Vrai
    retourner Faux

fonction EdmondsKarp(graph, source, puits):
    initialiser parent[v] ‚Üê None pour tout sommet v
    max_flow ‚Üê 0

    tant que BFS(source, puits) est Vrai :
        chemin ‚Üê reconstruit depuis parent[]
        path_flow ‚Üê +‚àû
        s ‚Üê puits
        tant que s ‚â† source :
            path_flow ‚Üê min(path_flow, graph[parent[s]][s])
            s ‚Üê parent[s]
        max_flow ‚Üê max_flow + path_flow

        mettre √† jour les capacit√©s r√©siduelles :
        v ‚Üê puits
        tant que v ‚â† source :
            u ‚Üê parent[v]
            graph[u][v] ‚Üê graph[u][v] - path_flow
            graph[v][u] ‚Üê graph[v][u] + path_flow
            v ‚Üê parent[v]

    retourner max_flow
```

5. Impl√©mentation et test de l'algorithme [Edmonds-Karp](./algos/ek.py)

6. Analyse de la complexit√© de l'algorithme Edmonds-Karp

L‚Äôalgorithme d‚ÄôEdmonds-Karp a une complexit√© temporelle de O(V √ó E¬≤), o√π V est le nombre de sommets et E le nombre d‚Äôar√™tes. Cette complexit√© vient du fait qu‚Äôil utilise une recherche en largeur (BFS) pour trouver les chemins augmentants les plus courts, ce qui prend O(E) par it√©ration, et qu‚Äôil peut y avoir au plus O(V √ó E) it√©rations. 

Du c√¥t√© m√©moire, il utilise O(E) d‚Äôespace pour stocker le tableau les parents.

7. Discuter des cas o√π Edmonds-Karp est pr√©f√©rable √† Ford-Fulkerson.

L‚Äôalgorithme d‚ÄôEdmonds-Karp est pr√©f√©rable √† Ford-Fulkerson dans les cas o√π l‚Äôon souhaite garantir une terminaison plus rapide, notamment lorsque les capacit√©s des ar√™tes sont grandes. En effet, Ford-Fulkerson simple peut effectuer un tr√®s grand nombre d‚Äôit√©rations si le flot est incr√©ment√© par de tr√®s petites quantit√©s (par exemple 1 unit√© √† la fois sur des capacit√©s tr√®s grandes), ce qui peut rendre sa complexit√© exponentielle dans le pire cas. Edmonds-Karp, en utilisant une recherche en largeur (BFS) pour toujours choisir le chemin augmentant le plus court (en nombre d‚Äôar√™tes), √©vite ce probl√®me et garantit une complexit√© polynomiale (O(V √ó E¬≤)). Il est donc particuli√®rement adapt√© aux grands graphes ou aux applications critiques (comme les r√©seaux de transport ou de communication) o√π la performance pr√©visible est essentielle.


# Exercice 5 : Tri rapide randomis√©

## Le tri rapide randomis√© [`rand`](./algos/rand_quicksort.py)

1. Ex√©cution :
```bash
python -m app.main rand
```

2. Exemple :
La commande trie la liste `[10, 7, 8, 9, 1, 5]` avec un pivot choisi al√©atoirement.

3. Comparaison :
```bash
python -m app.main rand-compare
```
Affiche le temps d‚Äôex√©cution pour le tri rapide d√©terministe et le tri randomis√© sur une grande liste.

4. Complexit√© :
- Moyenne : **O(n log n)**
- Pire cas : **O(n¬≤)** (si les pivots sont mal choisis)
- Meilleur cas : **O(n log n)**

5. Explication :
Le tri rapide randomis√© utilise un pivot al√©atoire √† chaque appel r√©cursif, ce qui permet de r√©duire la probabilit√© d'atteindre les pires cas.

---

# Exercice 6 : Arbres AVL

## Insertion et suppression dans un AVL [`tree-put`, `tree-del`](./algos/avl.py)

1. Insertion :
```bash
python -m app.main tree-put
```
Ins√®re les valeurs `[10, 20, 30, 40, 50, 25]` dans un arbre AVL.

2. Suppression :
```bash
python -m app.main tree-del
```
Supprime la valeur `30` de l‚Äôarbre pr√©c√©dent.

3. V√©rification d‚Äô√©quilibre :
```bash
python -m app.main tree-eq
```

4. Complexit√© :
- Insertion/Suppression/Requ√™tes : **O(log n)**
- Stockage : **O(n)**

5. Explication :
L‚Äôarbre AVL r√©√©quilibre automatiquement ses branches √† chaque insertion ou suppression via des rotations simples ou doubles pour maintenir une hauteur minimale.

---

# Exercice 7 : Probl√®mes NP-complets et NP-difficiles

## V√©rificateur SAT [`np-sat`](./algos/np_problems.py)

1. Ex√©cution :
```bash
python -m app.main np-sat
```

2. Formule test√©e :
```
(A ‚à® ¬¨B) ‚àß (B ‚à® C ‚à® ¬¨D) ‚àß (¬¨A ‚à® D)
```

3. Affectation utilis√©e :
```python
{"A": True, "B": False, "C": True, "D": True}
```

4. R√©sultat attendu :
```
Satisfiable = True
```

5. Explication :
Le SAT consiste √† v√©rifier si une formule bool√©enne est vraie pour une affectation. Ce v√©rificateur parcourt les clauses et retourne True si toutes sont satisfaites.

---

## Heuristique TSP [`np-tsp`](./algos/np_problems.py)

1. Ex√©cution :
```bash
python -m app.main np-tsp
```

2. Exemple de matrice (4 villes) :
```
A  B  C  D
A  0 10 15 20
B 10  0 35 25
C 15 35  0 30
D 20 25 30  0
```

3. R√©sultat attendu :
```
Chemin : [0, 1, 3, 2, 0] | Co√ªt : 80
```

4. Complexit√© :
- Approximative : **O(n¬≤)** (heuristique na√Øve)
- Exacte (brute force) : **O(n!)**

5. Explication :
Ce TSP utilise l‚Äôheuristique du plus proche voisin. Ce n‚Äôest pas optimal, mais efficace pour des petites instances.