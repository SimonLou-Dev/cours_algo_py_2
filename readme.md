# TP1 - S2 d'Algorithmique : Algorithmes de Graphes & Structures de DonnÃ©es

## ğŸ“¦ Installation

1. Clone ce dÃ©pÃ´t :
```bash
git clone https://github.com/ton-utilisateur/ton-projet.git
cd ton-projet
```

# Configuration du json

```json
{
  "matrice_start": "",
  "matrice": {
    "A": {"B": 4, "C": 2},
    "B": {"A": 4, "D": 5},
    "C": {"A": 2, "E": 3},
    "D": {"B": 5, "F": 6},
    "E": {"C": 3},
    "F": {"D": 6}
  }
}
```

`matrice_start` : sommet de dÃ©part pour le parcours du graphe
`matrice` : reprÃ©sentation du graphe sous forme de dictionnaire oÃ¹ chaque clÃ© est un sommet et la valeur est un dictionnaire des voisins avec les poids des arÃªtes.

# Exercice 1 : Recherche et Parcours de Graphes
## Le [BFS](./algos/bfs.py)
1. Execution
```bash
python main.py bfs
```
2. Temps d'Ã©xÃ©cution

Le BFS s'Ã©xecute en 0.99ms avec le graphe donnÃ©

3. ComplÃ©xitÃ©

Le BFS a une complexitÃ© temporelle de O(V + E) oÃ¹ V est le nombre de sommets et E le nombre d'arÃªtes du graphe. En effet, chaque sommet est visitÃ© une fois et chaque arÃªte est examinÃ©e une fois.

La complexitÃ© spatiale est Ã©galement O(V) car on doit stocker les sommets visitÃ©s et la file d'attente.

## Le DFS [dfs](./algos/dfs.py)
1. Execution
```bash
python main.py dfs
```
2. Temps d'Ã©xÃ©cution

Le DFS s'Ã©xecute en 0.99ms avec le graphe donnÃ©

3. ComplÃ©xitÃ©

Le DFS a une complexitÃ© temporelle de O(V + E) oÃ¹ V est le nombre de sommets et E le nombre d'arÃªtes du graphe. En effet, chaque sommet est visitÃ© une fois et chaque arÃªte est examinÃ©e une fois.
La complexitÃ© spatiale est O(V) car on doit stocker les sommets visitÃ©s et la pile d'appels rÃ©cursive.

## BFS avec dÃ©tection des composantes connexes [bfs connexe](./algos/bfs.py)
```bash
python main.py bfs-connexe 
```

## DFS avec dÃ©tÃ©ction de cycle [dfs cycle](./algos/dfs.py)
```bash
python main.py dfs_cycle
```
## PrÃ©fÃ©rence du DFS ou du BFS

TODO

# Exercice 2 : Algorithme de Dijkstra

1. Ecriture du pseudo code
```
EntrÃ©e :
    - G : graphe avec sommets et arÃªtes pondÃ©rÃ©es
    - S : sommet de dÃ©part

Initialisation :
    Pour chaque sommet v dans G :
        distance[v] â† âˆ
    distance[S] â† 0

    file_prioritÃ© â† file vide (ex: tas binaire)
    insÃ©rer (0, S) dans file_prioritÃ©   // (distance, sommet)

    visitÃ© â† ensemble vide

Tant que file_prioritÃ© nâ€™est pas vide :
    (d, u) â† extraire_min(file_prioritÃ©)

    Si u âˆˆ visitÃ© :
        continuer

    ajouter u Ã  visitÃ©

    Pour chaque voisin v de u :
        poids â† poids de lâ€™arÃªte (u, v)

        Si distance[u] + poids < distance[v] :
            distance[v] â† distance[u] + poids
            insÃ©rer (distance[v], v) dans file_prioritÃ©

Retourner distance

```

2. ImplÃ©mentation de l'algorithme [dijkstra](./algos/dijkstra.py)
```bash
python main.py dijkstra
```

3. RÃ©solution du problÃ¨me du plus court chemin

En appliquant lâ€™algorithme de Dijkstra depuis le sommet A, on obtient les distances minimales suivantes vers les autres sommets :
- A â†’ B : 4
- A â†’ C : 2
- A â†’ D : 9
- A â†’ E : 5
- A â†’ F : 15
Ces rÃ©sultats reprÃ©sentent les plus courts chemins en termes de coÃ»t total (somme des poids).

NB: la comparaise avec bellman ford et fair dans le 6. de la partie [Bellman-Ford](#exercice-3--algorithme-de-bellman-ford)

4. Analyse de la complexitÃ©

L'algorithme de Dijkstra a une complexitÃ© temporelle de O((V + E) * log(V)) oÃ¹ V est le nombre de sommets et E le nombre d'arÃªtes du graphe.
La complexitÃ© temporelle s'explique par le fait que chaque sommet est visitÃ© une fois et chaque arÃªte est examinÃ©e une fois. De plus, l'utilisation d'une file de prioritÃ© permet d'optimiser la recherche du sommet avec la distance minimale.

La complexitÃ© spatiale est O(V) car on doit stocker les sommets visitÃ©s et la file de prioritÃ©.

# Exercice 3 : Algorithme de Bellman-Ford


1. Pseudo code pour de Bellman-Ford

```
EntrÃ©e :
    - G : graphe avec sommets et arÃªtes pondÃ©rÃ©es
    - S : sommet de dÃ©part

Initialisation :
    Pour chaque sommet v dans G :
        distance[v] â† âˆ
    distance[S] â† 0

    Pour i allant de 0 Ã  nombre de sommet du graph - 1 : 
        Pour chaque sommet V dans G :
            Pour chaque voisin N de V :
                W <- poids entre V et N
                Si dinstance[V] + poid < distance[N] alors
                    distance[N] <- distance[V] + W
                fin Si
            Fin pour chaque
        Fin pour chaque
    Fin pour chaque

    # DÃ©tection des cycle nÃ©gatif
    Pour chaque sommet V dans G :
         Pour chaque voisin N de V :
            W <- poids entre V et N
            # S'il est encore possible d'amÃ©liorer les distance, alors le graph contuent un cycle nÃ©gatif
            Si distance[V] + W < distance[N] alors
                renvoyer "Le graph Ã  un cycle nÃ©gatif"
            Fin si
        fin pour chaque
    Fin pour chaque
    # Fin de la dÃ©tection de cycle nÃ©gatif

retourner distance
```

2. ImplÃ©mentation et test de l'algorithme [bellman-ford](./algos/bellman-ford.py)
```bash
python main.py bf
```

3. DÃ©tection des cycles nÃ©gatif

La dÃ©tection des cycles nÃ©gatif se fait grÃ¢ce Ã  la boucle suivante dans le pseudo-code
```
# DÃ©tection des cycle nÃ©gatif
    Pour chaque sommet V dans G :
         Pour chaque voisin N de V :
            W <- poids entre V et N
            # S'il est encore possible d'amÃ©liorer les distance, alors le graph contuent un cycle nÃ©gatif
            Si distance[V] + W < distance[N] alors
                renvoyer "Le graph Ã  un cycle nÃ©gatif"
            Fin si
        fin pour chaque
    Fin pour chaque
    # Fin de la dÃ©tection de cycle nÃ©gatif
```

Comment cela fonctionne ?
> GrÃ ce Ã  l'instruction `Pour i allant de 0 Ã  nombre de sommet du graph - 1` dans le pseudo-code, les distance minimal vont se propager jusqu'Ã  sommets les plus loins. Si il est encore possible d'amÃ©liorer ce rÃ©sultat alors que toutes les distances ont Ã©tÃ© propagÃ©es au plus loins, alors le graph contient un cycle nÃ©gatif.

Lancement du code

```bash
python main.py bf-neg
```

4. Les cycles nÃ©gatif dans la pratique
Les cycles nÃ©gatif ne peuvent pas s'appliquer dans les rÃ©seaux informatique car les distances ou les couts sont physique donc par dÃ©finition toujours positifs.

Dans un jeu vidÃ©o, un cycle nÃ©gatif peut reprÃ©senter une boucle dâ€™actions oÃ¹ le joueur gagne constamment des points ou des ressources, ce qui casse lâ€™Ã©quilibre du jeu.
> Exemple : Dans un RPG, un joueur dÃ©couvre quâ€™il peut acheter une potion pour 5 piÃ¨ces dâ€™or, la revendre pour 6 piÃ¨ces dans une autre ville, puis revenir â€” en boucle â€” gagnant 1 piÃ¨ce Ã  chaque cycle sans fin. Ce cycle Ã©conomique "achete â†’ voyage â†’ revend â†’ revient" correspond Ã  un cycle nÃ©gatif de coÃ»t qui exploite une faille dans l'Ã©quilibrage du jeux.

5. Analyse de complexitÃ©

La complexitÃ© temporelle de Bellman-Ford est O(VE), car on parcourt toutes les arÃªtes E pendant V - 1 itÃ©rations (oÃ¹ V est le nombre de sommets). Cela donne une complexitÃ© de O((V - 1) * E), et comme le -E est nÃ©gligeable face Ã  VE, on retient O(VE).

La complexitÃ© spatiale est O(V), car on stocke uniquement un tableau (ou dictionnaire) de distances pour chaque sommet.

6. Comparaison avec Dijkstra

Lâ€™algorithme de Bellman-Ford permet de calculer les plus courts chemins depuis un sommet, mÃªme en prÃ©sence de poids nÃ©gatifs, et peut dÃ©tecter les cycles de poids nÃ©gatif. En revanche, il est plus lent avec une complexitÃ© en temps de O(VE). Lâ€™algorithme de Dijkstra est plus rapide (O((V + E) log V)) mais ne fonctionne que si tous les poids sont positifs. Dijkstra est donc souvent prÃ©fÃ©rÃ© pour les graphes classiques (rÃ©seaux, cartes), tandis que Bellman-Ford est utile pour des cas plus gÃ©nÃ©raux ou complexes. Le choix dÃ©pend du type de graphe et des contraintes sur les poids.

# Exercice 4 : l'algorithmes de Ford-Fulkerson et Edmonds-Karp

1. Pseudo code Ford-Fulkerson

```
fonction BFS(source, puits, graph, parent):
    initialiser file â† [source]
    initialiser ensemble visitÃ© â† {source}
    tant que la file nâ€™est pas vide :
        u â† retirer un sommet de la file
        pour chaque voisin v de u :
            si v non visitÃ© et capacitÃ© rÃ©siduelle (u, v) > 0 :
                file â† file + [v]
                parent[v] â† u
                ajouter v Ã  visitÃ©
                si v == puits :
                    retourner Vrai
    retourner Faux

fonction FordFulkerson(graph, source, puits):
    initialiser parent[v] â† None pour chaque sommet v
    flot_max â† 0

    tant que BFS(source, puits) retourne Vrai :
        chemin â† chemin reconstruit depuis parent
        flot_chemin â† capacitÃ© minimale sur ce chemin
        pour chaque arÃªte (u, v) du chemin :
            diminuer capacitÃ© de (u, v) de flot_chemin
            augmenter capacitÃ© de (v, u) de flot_chemin
        flot_max â† flot_max + flot_chemin

    retourner flot_max
```


2. ImplÃ©mentation et test de l'algorithme [Ford-Fulkerson](./algos/ff.py)
```bash
python main.py ff
```

3. Analyse de la complexitÃ© de l'algorithme Ford-Fulkerson

La complexitÃ© temporelle de lâ€™algorithme de Ford-Fulkerson dÃ©pend du nombre dâ€™itÃ©rations nÃ©cessaires pour atteindre le flot maximal. Ã€ chaque itÃ©ration, on cherche un chemin augmentant, ce qui prend O(E) dans le cas dâ€™une recherche en profondeur (DFS), et le flot est augmentÃ© dâ€™au moins une unitÃ© Ã  chaque fois. Si le flot maximum est F, la complexitÃ© temporelle est donc O(F Ã— E).

La complexitÃ© spatiale, lâ€™algorithme utilise un dictionnaire pour suivre les parents des sommets soit O(V).

4. Pseudo code Edmonds-Karp

```
fonction BFS(source, puits,  graph, parent):
    crÃ©er une file queue â† [source]
    crÃ©er un ensemble visitÃ© â† {source}
    tant que queue nâ€™est pas vide :
        u â† queue.pop()
        pour chaque voisin v de u :
            si v non visitÃ© et capacitÃ© rÃ©siduelle graph[u][v] > 0 :
                parent[v] â† u
                ajouter v Ã  queue
                ajouter v Ã  visitÃ©
                si v = puits :
                    retourner Vrai
    retourner Faux

fonction EdmondsKarp(graph, source, puits):
    initialiser parent[v] â† None pour tout sommet v
    max_flow â† 0

    tant que BFS(source, puits) est Vrai :
        chemin â† reconstruit depuis parent[]
        path_flow â† +âˆ
        s â† puits
        tant que s â‰  source :
            path_flow â† min(path_flow, graph[parent[s]][s])
            s â† parent[s]
        max_flow â† max_flow + path_flow

        mettre Ã  jour les capacitÃ©s rÃ©siduelles :
        v â† puits
        tant que v â‰  source :
            u â† parent[v]
            graph[u][v] â† graph[u][v] - path_flow
            graph[v][u] â† graph[v][u] + path_flow
            v â† parent[v]

    retourner max_flow
```

5. ImplÃ©mentation et test de l'algorithme [Edmonds-Karp](./algos/ek.py)

6. Analyse de la complexitÃ© de l'algorithme Edmonds-Karp

Lâ€™algorithme dâ€™Edmonds-Karp a une complexitÃ© temporelle de O(V Ã— EÂ²), oÃ¹ V est le nombre de sommets et E le nombre dâ€™arÃªtes. Cette complexitÃ© vient du fait quâ€™il utilise une recherche en largeur (BFS) pour trouver les chemins augmentants les plus courts, ce qui prend O(E) par itÃ©ration, et quâ€™il peut y avoir au plus O(V Ã— E) itÃ©rations. 

Du cÃ´tÃ© mÃ©moire, il utilise O(E) dâ€™espace pour stocker le tableau les parents.

7. Discuter des cas oÃ¹ Edmonds-Karp est prÃ©fÃ©rable Ã  Ford-Fulkerson.

Lâ€™algorithme dâ€™Edmonds-Karp est prÃ©fÃ©rable Ã  Ford-Fulkerson dans les cas oÃ¹ lâ€™on souhaite garantir une terminaison plus rapide, notamment lorsque les capacitÃ©s des arÃªtes sont grandes. En effet, Ford-Fulkerson simple peut effectuer un trÃ¨s grand nombre dâ€™itÃ©rations si le flot est incrÃ©mentÃ© par de trÃ¨s petites quantitÃ©s (par exemple 1 unitÃ© Ã  la fois sur des capacitÃ©s trÃ¨s grandes), ce qui peut rendre sa complexitÃ© exponentielle dans le pire cas. Edmonds-Karp, en utilisant une recherche en largeur (BFS) pour toujours choisir le chemin augmentant le plus court (en nombre dâ€™arÃªtes), Ã©vite ce problÃ¨me et garantit une complexitÃ© polynomiale (O(V Ã— EÂ²)). Il est donc particuliÃ¨rement adaptÃ© aux grands graphes ou aux applications critiques (comme les rÃ©seaux de transport ou de communication) oÃ¹ la performance prÃ©visible est essentielle.
